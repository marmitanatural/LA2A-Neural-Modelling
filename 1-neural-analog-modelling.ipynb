{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Analog Modelling \n",
    "Please note that the dataset used for this project is not 100% clean, and the errors from the authors errata page are addressed and resolved in the other notebook `0-data-validation.ipynb`. This is done to ensure that in the below our models are not impacted.\n",
    "### -- Introduction\n",
    "This repo is concerned with modelling analog effects with neural networks. Why? Mostly for curiosity.\n",
    "\n",
    "Most VST effects are typically implemented in C++, using handy frameworks like JUCE which contains libraries to handle many of the typical challenges of plugin design such as cross-platform functionality, DSP, frontend design.. In order to do real analog modelling, one typically needs to have some high level domain knowledge and have the capacity to understand complicated analog circuits present in analog synths and effects, as well as a knowledge of DSP which allows us to model these signals numerically. Other approaches include simulation of physical processes like reverberation.\n",
    "\n",
    "In principle, neural networks are a more high level approach which, presupposing the access to a relevant dataset of dry/wet signals, allow us to model the effects without having to bust out Korg manuals from the 1980s and examine the intricacies of the circuits for their wonderful filters. \n",
    "\n",
    "There are clearly many limits in using neural networks to process audio. Some include:\n",
    "- Clean datasets of dry/wet signals are not typically easy to come by, and are labour intensive to repair. Hence NNs are not always a suitable approach for modelling analog effects.\n",
    "- Neural networks are typically quite bulky, and implemented in Python (which is typically slower compared to DSP implementations in C++). Although not impossible (see work of [C. Steinmetz](https://scholar.google.com/citations?user=jSvSfIMAAAAJ&hl=en)), this makes it difficult to use neural networks to process signals in real time. This inherent slowness makes a lot of neural approaches only suitable to asynchronous audio processing. Sequence to sequence audio modelling is notoriously slow, especially given the large size of common audio models used today e.g [Demucs](https://github.com/facebookresearch/demucs) (for source separation). \n",
    "\n",
    "I am interesting in exploring these limits, especially the second one. \n",
    "\n",
    "### -- Data \n",
    "In this case, we use the [SignalTrain](https://zenodo.org/records/3824876) dataset from 2019 which contains various dry and wet recordings, where the wet recordings are processed with an analog compressor, the Universal Audio LA-2A. \n",
    "\n",
    "This compressor is a very simple one, and we will be concerned with modelling the signal using only two parameters on the compressor:\n",
    "- The switch between compression and limiting\n",
    "- The peak reduction\n",
    "\n",
    "The information about the parameters of the compressor are contained in the file names. In particular, the value between 0-100 represents the peak reduction knob, whereas the binary value 0/1 represents the switch between compression (0) and limiting (1). The authors say that there was no changes to the input or output gains, and that only these two parameters above were changed during recording.\n",
    "\n",
    "### -- Audio\n",
    "The audio in this dataset has a sampling rate of 44.1kHz and is mono, as the original analog LA-2A was designed to process mono signals. The individual audio files actually contain a \"collage\" of different pieces of music which are stitched seamlessly together. The whole recording will be passed through the compressor to obtain the wet signal.\n",
    "\n",
    "I followed the advice of the authors in cleaning up errors in the dataset (removing / moving certain files) in other notebook `data_validation.ipynb`. I cross correlated all the signals to see if any signals except those mentioned by the authors had a phase shift between the dry and wet signals. To simplify my life, I found all the signals which had a relative phase shift and removed them, keeping only perfectly correlated dry/ wet pairs; which to the credit of the authors, was the vast majority of the signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressors\n",
    "\n",
    "In the context of music production we are interested in Dynamic Range Compressors. These are effects which reduce the dynamic range (the gap between the loudest and quietest parts of a signal) via downward or upward compression (reducing the gain of loud sounds, and increasing the gain of quiet sounds respectively). They have several parameters, the most important ones being:\n",
    "\n",
    "- Threshold: the volume at which the compressor will be activated. In the case of downward compression, if the threshold is -6dB, and the signal peaks at -10dB, the compressor will never be activated, if it is, the compressor will activate and trigger gain reduction.  On the other hand, in upward compression, if the threshold is -6dB, any sound below this threshold (e.g -10dB) will activate the compression and cause a gain increase.\n",
    "\n",
    "- Ratio: a parameter which controls the amount of compression applied to an incoming signal. It is called a ratio because it is typically defined in such a way that if the ratio is 4:1, any signal 4dB **over** the threshold will be reduced to 1dB over the threshold.\n",
    "\n",
    "Some other common parameters include attack and release, which delay or extend resp. the activation of the compressor. e.g if the attack is 50ms, when the compressor detects a signal which crosses the threshold, it will delay its activation by 50ms. The release, if 50ms, will extend the action of the compressor by 50ms. The effect of attack / release is often not considered in a step function like manner, but will often be smoother, where for example during the attack phase of 50ms after the detection of a signal crossing the compressor's threshold, the action of the compressor may be linearly ramped up to its full action. \n",
    "\n",
    "Another important control is the \"knee\" setting. In the case of a \"hard knee\" compressor, the compression will only activate once the signal crosses the threshold, triggering gain reduction. In the case of a soft knee compressor, this transition point is 'blurred' and less abrupt, even for signals below the threshold, the gain may be attenuated slightly by the compressor. This results in a 'smoother' transition between compressor and uncompressed parts of the signal. \n",
    "\n",
    "Here is an example of a minimal compressor implemented in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compressor(signal, threshold, ratio):\n",
    "    compressed_signal = np.zeros_like(signal)\n",
    "    for i in range(len(signal)):\n",
    "        if np.abs(signal[i]) > threshold:\n",
    "            compressed_signal[i] = np.sign(signal[i]) * (threshold + (np.abs(signal[i]) - threshold) / ratio)\n",
    "        else:\n",
    "            compressed_signal[i] = signal[i]\n",
    "    return compressed_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something important to remember is the units in which you are working. In a 16 bit system, a sample can take any value between -32768 and +32767 (2^16 values hence 16 \"bit\"). If a signal exceeds this maximum value, it may result in clipping (the value of the signal will be cut off at the maximum value). From these raw numbers, we can define the dBFS units (decibels relative to full scale), where here our \"full scale\" value will be the maximum value of our amplitude in our 16 bit system, +32767. The conversion can be defined as $ X \\text(dB) = 20 \\text{log}_{10} \\left( \\frac{\\text{Amplitude}}{32767} \\right)$. If we reach our max value, notice that the corresponding value in dBFS will be 0dB, as expected. \n",
    "\n",
    "dB is commonly used because humans have a logarithmic perception of volume - i.e doubling the intensity of a signal will not be perceived by humans as \"twice as loud\" indeed the human perception of loudness more closely mimics that of the logarithm of intensity, rather than a linear relationship - interestingly, loudness is a \"psychological\" quantity, and humans even have different perceptions of loudness depending on the frequency of the incoming signal - that means that a signal at 2kHz and 15kHz with the same intensity will not be perceived as the same loudness by a human. For further details you can read about Fletcher-Munson curves which discuss this phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Preparation \n",
    "It is common when working with data such as audio to keep a metadata dataframe which contains important information about the audio that is not contained in the raw audio signal, so that we can feed this information to our model. Whether compression or limiting is being applied is an example of such metadata. The authors did not include such a metadata frame i.e a df with each row being a track, with a unique id, the paths to the raw and processed audio, and the compression settings applied, so we have to create it ourselves from the filenames provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data consists of some raw audio files of the form e.g `./data/<split>/input_XXX_.wav` and some corresponding processed audio files `./data/<split>.target_XXX_LA2A_YY__Z__WW.wav`. The compression parameters are contained in the file name of the processed file. The parameters are the following:\n",
    "- XXX: audio file id\n",
    "- YY: seems to be the compressor revision, not that important\n",
    "- Z: compressor/limiter switch either 0 or 1. \n",
    "- WW: peak reduction switch, from 0-100. \n",
    "\n",
    "In the other notebook I already removed pairs of audio which were out of phase (an error in the creation of the dataset), so we can proceed with extracting the data from the track files as described above. \n",
    "\n",
    " The input data will be:\n",
    "- Raw audio segment.\n",
    "- Compressor / Limiter Switch (0 or 1 resp.).\n",
    "- Compressor peak reduction (0 - 100).\n",
    "Where the target will be the corresponding processed audio segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique track ids by parsing the info in the file names\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_track_ids(track_paths):\n",
    "    \"\"\"\n",
    "    Gets a list of track_ids which are unique from the given track_paths\n",
    "    \"\"\"\n",
    "    track_ids = [track_path.split(\"_\")[1] for track_path in track_paths]\n",
    "    numeric_ids_only = [track for track in track_ids if track.isdigit()]\n",
    "    return list(set(numeric_ids_only))\n",
    "\n",
    "\n",
    "def prepare_metadata_records(splits):\n",
    "    \"\"\"\n",
    "    Gets a set of parsed metadata records for every track in each split.\n",
    "    - Creates a dict with split names as keys e.g {'train': .., 'test': .., ..}\n",
    "    - The value corresponding to each split name is a list of nested records of the form [{'track_id':{'X_path':xxx, 'param1':yyy, 'param2':zzz, 'Y_path':www}, ..]\n",
    "    \"\"\"\n",
    "    metadata = defaultdict(list)\n",
    "    for split in splits:\n",
    "        split_name = split.split(\"/\")[-2].lower()  # unfortunate naming of variable here\n",
    "        track_paths = os.listdir(split)\n",
    "        track_ids = get_track_ids(track_paths)\n",
    "\n",
    "        split_metadata = []\n",
    "        for track_id in track_ids:\n",
    "            track_level_data = defaultdict(dict)\n",
    "            for track_path in track_paths:\n",
    "                if track_id in track_path and \"target\" in track_path:\n",
    "                    split_path = track_path.split(\"_\")\n",
    "                    compress_or_limit = split_path[-3]\n",
    "                    peak_reduction = split_path[-1].split(\".wav\")[0]\n",
    "\n",
    "                    track_level_data[track_id][\"raw_audio_path\"] = (\n",
    "                        split + \"input_\" + track_id + \"_.wav\"\n",
    "                    )\n",
    "                    track_level_data[track_id][\"compress_or_limit\"] = compress_or_limit\n",
    "                    track_level_data[track_id][\"peak_reduction\"] = peak_reduction\n",
    "                    track_level_data[track_id][\"processed_audio_path\"] = (\n",
    "                        split + track_path\n",
    "                    )\n",
    "            split_metadata.append(track_level_data)\n",
    "        metadata[split_name] = split_metadata\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def turn_records_into_df(records):\n",
    "    \"\"\"\n",
    "    Turns the metadata records into a nice and simple dataframe\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    for split, records in records.items():\n",
    "        for record in records:\n",
    "            for record_id, details in record.items():\n",
    "                flattened_data.append(\n",
    "                    {\"split\": split, \"track_id\": record_id, **details}\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "\n",
    "splits = [\"./data/Train/\", \"./data/Test/\", \"./data/Val/\"]\n",
    "records = prepare_metadata_records(splits)\n",
    "df = turn_records_into_df(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our basic metadata df that will allow us to prepare each small audio segment for training, let's just do a quick sanity check to make sure we have no parsing errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split                   0\n",
       "track_id                0\n",
       "raw_audio_path          0\n",
       "compress_or_limit       0\n",
       "peak_reduction          0\n",
       "processed_audio_path    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.track_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, no NaNs or duplicates. Let's just fix the types of some columns as our model will need them to have the correct types later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"track_id\"] = df[\"track_id\"].astype(int)\n",
    "df[\"compress_or_limit\"] = df[\"compress_or_limit\"].astype(int)\n",
    "df[\"peak_reduction\"] = df[\"peak_reduction\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Audio Segments for Training + Evaluation + Challenges\n",
    "Each file in the dataset is not a unique track, but rather a very long (can be up to 20 minutes) collage of different tracks, stitched together without interruption. All tracks in the file are compressed with the same compression parameters indicated in the \"target\" file name. We also have access to the raw, uncompressed audio file corresponding to this.\n",
    "\n",
    "Our model will not have an input size of 20 minutes and will not handle variable input sizes effectively, so we need to break each file into chunks of 3-10 seconds and process them one by one, these are common input sizes in the literature for audio ML (e.g ShortChunk has 15 seconds, whereas MusiCNN has 3 seconds). \n",
    "\n",
    "This means that from 1 file of 20 minutes, we will actually many training examples for a model with 1 second input length. \n",
    "\n",
    "It also means that during inference (i.e during modelling) we will not be able to process a whole file at once but will need to split the incoming audio into 3 second chunks and then process each chunk separately. We will call the incoming audio chunk the \"buffer\". This fact is actually a serious design challenge for modelling a time based effect such as compression, because a naive model architecture means it will only use incoming audio in the buffer to produce an output - but time based effects like compression have parameters such as attack/release (discussed above) which means audio in the buffer should trigger compression in the next incoming buffer. If this is not clear, imagine that our 3 second audio signal in the buffer has a loud peak at 2.99s. If our compressor has an attack time of 0,015s (15ms), the compression will only \"kick in\" or be triggered _after_ the current signal is out of the buffer (2.99 + 0.15 > 3.0), affecting only the start of the next 3 second signal coming into the buffer. This means there is a potential dependency between windows that are being processed independently by our model. The same problem exists in the realm of DSP audio plugin design, where these \"transient\" errors are often treated using a lookahead buffer. This challenge may end up motivating the design of our model later if naive models prove to suffer from this possible complication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load a full 15-20 minute audio file and split it up into windows of size 1 seconds. We will have a window stride of 0.5 second. This means that we will keep a bit of the \"last\" window in the current window, which is a common technique in audio processing / time series analysis to have smoother transitions between adjacent windows. Let's make a helper function that will take an object of size N, a window of size K (K <= N) and a stride length S and compute how many overlapping intervals we can compute from our audio. For an example of what this means look below for an explicit example."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- - - - -\n",
    "\n",
    "- - \n",
    "  - -\n",
    "    - -\n",
    "      - -\n",
    "\n",
    "-> 4 overlapping intervals of size 2 and stride 1 fit in object of length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_interval_count(object_size, window_size, window_stride):\n",
    "    \"\"\"all lengths in samples here\"\"\"\n",
    "    stride = 0\n",
    "    count = 0\n",
    "    while True:\n",
    "        pos = stride + window_size \n",
    "        if pos >= object_size:\n",
    "            return count + 1 # gives number of overlapping intervals that fit in the \n",
    "        count += 1\n",
    "        stride += window_stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import audiofile\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_audio_paths,\n",
    "        target_audio_paths,\n",
    "        window_size,\n",
    "        overlap,\n",
    "        params=None,\n",
    "    ):\n",
    "        self.input_audio_paths = input_audio_paths\n",
    "        self.target_audio_paths = target_audio_paths\n",
    "        self.window_size = window_size  # in seconds\n",
    "        self.window_size_samples = self.window_size * 44100 # in samples\n",
    "        self.overlap = overlap  # in seconds\n",
    "        self.overlap_samples = self.overlap * 44100 # in samples\n",
    "        self.params = params  # compressor parameters i.e compress-limit switch, peak reduction\n",
    "        self.window_to_audio_mapping = self.window_index_to_audio_indices() # map an\n",
    "        self.examples = self.create_examples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, window_index):\n",
    "        \"\"\" \n",
    "        Converts a window index to a tuple of audio indices, i.e the first window (0)\n",
    "        corresponds to the first audio (0) and the first window in this audio (0). \n",
    "\n",
    "        The set of {window_index: (audio_index, window_index_in_audio)} is precomputed \n",
    "        in the `self.window_to_audio_mapping method`. \n",
    "        \n",
    "        We use this tuple of indices to \n",
    "        load the actual audio data (the stream of samples), lazily, for training. \n",
    "        \"\"\"\n",
    "        audio_index, window_index_in_audio = self.window_to_audio_mapping[window_index]\n",
    "        input_audio_path, target_audio_path, params = self.examples[audio_index]\n",
    "\n",
    "        input_waveform, _ = audiofile.read(input_audio_path, offset=(window_index_in_audio*self.overlap_samples)/44100, duration=self.window_size)\n",
    "        target_waveform, _ = audiofile.read(target_audio_path, offset=(window_index_in_audio*self.overlap_samples)/44100, duration=self.window_size)\n",
    "\n",
    "        input_waveform = (input_waveform + 1.0) / 2.0 # Rescale (invertibly) values that go from -1 to 1, to be between 0 and 1\n",
    "        target_waveform = (target_waveform + 1.0) / 2.0 \n",
    "\n",
    "        input_waveform = torch.tensor(input_waveform, dtype=torch.float32)\n",
    "        target_waveform = torch.tensor(target_waveform, dtype=torch.float32)\n",
    "        compress_limit = torch.tensor(params[0], dtype=torch.float32)\n",
    "        peak_reduction = torch.tensor(params[1]/100.0, dtype=torch.float32) # Ensure the peak reduction is between 0 and 1, not 0 - 100\n",
    "\n",
    "        return (input_waveform, compress_limit, peak_reduction), target_waveform\n",
    "\n",
    "    def window_index_to_audio_indices(self):\n",
    "        \"\"\" \n",
    "        Our audio dataset constructor takes in a list of input/target audio paths. In the SignalTrain dataset, each \n",
    "        individual audio is very long, up to 20 mins. Our model will have a much smaller input size. Therefore, we \n",
    "        will use a given audio file to create several training examples by taking overlapping windows of for example 3 seconds \n",
    "        from each file. e.g 0-3s, 1-4s, 2-5s all the way up until we use all 20 minutes of the audio file.\n",
    "\n",
    "        Since __getitem__ method is lazy, it will try to load each window of audio data on the fly instead of preparing\n",
    "        them in advance. This means that when we say __getitem__(293), we need to know which audio file corresponds to \n",
    "        window 293, and where precisely this window is situated in that audio file, so that we can load the right data.\n",
    "        \n",
    "        For example, window with index 0 can be identified with the first audio file, and the first window in that audio i.e (0,0).\n",
    "        \n",
    "        This function is used to pre-compute the mapping from a window index into a tuple of indices identifying both the audio file,\n",
    "        and the position of this window in that audio file so that we can load the audio data on the fly in __getitem__. \n",
    "        \"\"\"\n",
    "        cumulative_window_index = 0\n",
    "        mapping = {}\n",
    "        for audio_index, path in enumerate(self.input_audio_paths):\n",
    "            num_windows = self.calculate_num_windows(path)\n",
    "            for i in range(num_windows):\n",
    "                mapping[cumulative_window_index + i] = (\n",
    "                    audio_index,\n",
    "                    i,\n",
    "                )  # e.g (3rd audio, 4th window of 3rd audio)\n",
    "            cumulative_window_index += num_windows\n",
    "        self.dataset_size = len(mapping)\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def calculate_num_windows(self, audio_path):\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        window_samples = self.window_size * sample_rate\n",
    "        overlap_samples = self.overlap * sample_rate\n",
    "        num_windows = overlapping_interval_count(\n",
    "            waveform.size(1), window_samples, overlap_samples\n",
    "        )\n",
    "        return num_windows\n",
    "\n",
    "    def create_examples(self):\n",
    "        return list(zip(self.input_audio_paths, self.target_audio_paths, self.params))\n",
    "\n",
    "\n",
    "# Example usage with multiple paths and parameters\n",
    "train_df = df[df.split == \"train\"]\n",
    "test_df = df[df.split == \"test\"]\n",
    "val_df = df[df.split == \"val\"]\n",
    "\n",
    "train_dataset = AudioDataset(\n",
    "    train_df[\"raw_audio_path\"].to_list(),\n",
    "    train_df[\"processed_audio_path\"].to_list(),\n",
    "    window_size=0.02,\n",
    "    overlap=0.01,\n",
    "    params=list(zip(train_df[\"compress_or_limit\"], train_df[\"peak_reduction\"])),\n",
    ")\n",
    "test_dataset = AudioDataset(\n",
    "    test_df[\"raw_audio_path\"].to_list(),\n",
    "    test_df[\"processed_audio_path\"].to_list(),\n",
    "    window_size=0.02,\n",
    "    overlap=0.01,\n",
    "    params=list(zip(test_df[\"compress_or_limit\"], test_df[\"peak_reduction\"])),\n",
    ")\n",
    "val_dataset = AudioDataset(\n",
    "    val_df[\"raw_audio_path\"].to_list(),\n",
    "    val_df[\"processed_audio_path\"].to_list(),\n",
    "    window_size=0.02,\n",
    "    overlap=0.01,\n",
    "    params=list(zip(val_df[\"compress_or_limit\"], val_df[\"peak_reduction\"])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "- Torchaudio loads audio as a tuple containing a 2D tensor and the sample rate. The 2D tensor is structured as (num_channels, num_frames). In the case of mono audio (1 channel), it still follows this format, but with the number of channels being 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of what our input / output data will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input waveform:\n",
      "tensor([0.4536, 0.4522, 0.4511, 0.4502, 0.4496, 0.4493, 0.4491, 0.4492, 0.4496,\n",
      "        0.4504, 0.4515, 0.4529, 0.4548, 0.4570, 0.4595, 0.4624, 0.4657, 0.4694,\n",
      "        0.4735, 0.4781, 0.4830, 0.4882, 0.4933, 0.4983, 0.5028, 0.5070, 0.5107,\n",
      "        0.5139, 0.5166, 0.5190, 0.5212, 0.5234, 0.5254, 0.5274, 0.5294, 0.5313,\n",
      "        0.5333, 0.5352, 0.5372, 0.5392, 0.5409, 0.5423, 0.5433, 0.5436, 0.5431,\n",
      "        0.5419, 0.5400, 0.5375, 0.5345, 0.5312, 0.5277, 0.5242, 0.5207, 0.5174,\n",
      "        0.5144, 0.5115, 0.5087, 0.5058, 0.5028, 0.4996, 0.4962, 0.4927, 0.4891,\n",
      "        0.4855, 0.4822, 0.4792, 0.4766, 0.4745, 0.4728, 0.4715, 0.4704, 0.4696,\n",
      "        0.4689, 0.4683, 0.4680, 0.4680, 0.4682, 0.4684, 0.4689, 0.4697, 0.4706,\n",
      "        0.4715, 0.4727, 0.4741, 0.4759, 0.4780, 0.4807, 0.4838, 0.4874, 0.4912,\n",
      "        0.4954, 0.4996, 0.5039, 0.5079, 0.5116, 0.5150, 0.5180, 0.5206, 0.5229,\n",
      "        0.5249, 0.5266, 0.5280, 0.5293, 0.5304, 0.5314, 0.5323, 0.5333, 0.5342,\n",
      "        0.5353, 0.5363, 0.5374, 0.5381, 0.5386, 0.5386, 0.5382, 0.5372, 0.5356,\n",
      "        0.5334, 0.5309, 0.5281, 0.5253, 0.5226, 0.5199, 0.5173, 0.5148, 0.5124,\n",
      "        0.5100, 0.5073, 0.5045, 0.5016, 0.4983, 0.4949, 0.4915, 0.4881, 0.4848,\n",
      "        0.4817, 0.4788, 0.4763, 0.4741, 0.4722, 0.4706, 0.4693, 0.4684, 0.4677,\n",
      "        0.4672, 0.4669, 0.4668, 0.4670, 0.4673, 0.4677, 0.4681, 0.4686, 0.4693,\n",
      "        0.4702, 0.4714, 0.4729, 0.4748, 0.4772, 0.4800, 0.4831, 0.4864, 0.4896,\n",
      "        0.4928, 0.4957, 0.4981, 0.5005, 0.5025, 0.5043, 0.5060, 0.5074, 0.5088,\n",
      "        0.5101, 0.5115, 0.5129, 0.5146, 0.5165, 0.5186, 0.5207, 0.5231, 0.5254,\n",
      "        0.5277, 0.5297, 0.5314, 0.5325, 0.5331, 0.5331, 0.5326, 0.5315, 0.5298,\n",
      "        0.5279, 0.5257, 0.5233, 0.5209, 0.5186, 0.5163, 0.5139, 0.5114, 0.5086,\n",
      "        0.5055, 0.5021, 0.4985, 0.4947, 0.4908, 0.4871, 0.4836, 0.4802, 0.4771,\n",
      "        0.4741, 0.4715, 0.4690, 0.4668, 0.4649, 0.4631, 0.4616, 0.4603, 0.4591,\n",
      "        0.4580, 0.4571, 0.4563, 0.4556, 0.4550, 0.4548, 0.4547, 0.4551, 0.4559,\n",
      "        0.4573, 0.4594, 0.4621, 0.4655, 0.4694, 0.4736, 0.4781, 0.4826, 0.4871,\n",
      "        0.4914, 0.4955, 0.4994, 0.5031, 0.5067, 0.5102, 0.5135, 0.5166, 0.5196,\n",
      "        0.5227, 0.5256, 0.5286, 0.5316, 0.5347, 0.5379, 0.5410, 0.5440, 0.5468,\n",
      "        0.5491, 0.5508, 0.5519, 0.5523, 0.5522, 0.5514, 0.5501, 0.5484, 0.5464,\n",
      "        0.5444, 0.5424, 0.5403, 0.5380, 0.5356, 0.5329, 0.5298, 0.5264, 0.5226,\n",
      "        0.5184, 0.5140, 0.5095, 0.5049, 0.5003, 0.4957, 0.4913, 0.4871, 0.4831,\n",
      "        0.4795, 0.4762, 0.4733, 0.4708, 0.4687, 0.4671, 0.4658, 0.4648, 0.4639,\n",
      "        0.4632, 0.4625, 0.4619, 0.4615, 0.4613, 0.4617, 0.4627, 0.4643, 0.4665,\n",
      "        0.4694, 0.4728, 0.4765, 0.4804, 0.4845, 0.4885, 0.4925, 0.4963, 0.4998,\n",
      "        0.5031, 0.5061, 0.5088, 0.5112, 0.5133, 0.5153, 0.5172, 0.5190, 0.5208,\n",
      "        0.5227, 0.5247, 0.5268, 0.5289, 0.5310, 0.5330, 0.5347, 0.5358, 0.5364,\n",
      "        0.5363, 0.5354, 0.5337, 0.5314, 0.5287, 0.5258, 0.5228, 0.5197, 0.5166,\n",
      "        0.5134, 0.5102, 0.5069, 0.5036, 0.5002, 0.4968, 0.4934, 0.4899, 0.4865,\n",
      "        0.4831, 0.4797, 0.4765, 0.4734, 0.4706, 0.4679, 0.4656, 0.4638, 0.4623,\n",
      "        0.4612, 0.4606, 0.4603, 0.4604, 0.4606, 0.4609, 0.4612, 0.4615, 0.4617,\n",
      "        0.4621, 0.4625, 0.4631, 0.4641, 0.4657, 0.4677, 0.4704, 0.4735, 0.4770,\n",
      "        0.4808, 0.4847, 0.4887, 0.4927, 0.4967, 0.5005, 0.5041, 0.5075, 0.5106,\n",
      "        0.5134, 0.5157, 0.5176, 0.5193, 0.5207, 0.5220, 0.5232, 0.5245, 0.5259,\n",
      "        0.5274, 0.5290, 0.5307, 0.5322, 0.5336, 0.5347, 0.5355, 0.5359, 0.5357,\n",
      "        0.5350, 0.5340, 0.5325, 0.5310, 0.5293, 0.5274, 0.5255, 0.5236, 0.5216,\n",
      "        0.5195, 0.5172, 0.5149, 0.5124, 0.5096, 0.5068, 0.5037, 0.5006, 0.4974,\n",
      "        0.4942, 0.4910, 0.4878, 0.4847, 0.4818, 0.4792, 0.4772, 0.4756, 0.4744,\n",
      "        0.4736, 0.4731, 0.4727, 0.4724, 0.4720, 0.4716, 0.4713, 0.4710, 0.4708,\n",
      "        0.4708, 0.4711, 0.4719, 0.4732, 0.4749, 0.4771, 0.4795, 0.4823, 0.4853,\n",
      "        0.4884, 0.4914, 0.4944, 0.4973, 0.5001, 0.5027, 0.5051, 0.5073, 0.5093,\n",
      "        0.5113, 0.5130, 0.5147, 0.5163, 0.5180, 0.5200, 0.5221, 0.5245, 0.5271,\n",
      "        0.5298, 0.5323, 0.5347, 0.5366, 0.5381, 0.5392, 0.5397, 0.5397, 0.5393,\n",
      "        0.5385, 0.5373, 0.5360, 0.5344, 0.5327, 0.5308, 0.5287, 0.5263, 0.5238,\n",
      "        0.5210, 0.5181, 0.5150, 0.5117, 0.5084, 0.5049, 0.5015, 0.4980, 0.4945,\n",
      "        0.4910, 0.4877, 0.4846, 0.4816, 0.4790, 0.4766, 0.4745, 0.4727, 0.4709,\n",
      "        0.4690, 0.4670, 0.4648, 0.4625, 0.4601, 0.4578, 0.4558, 0.4543, 0.4533,\n",
      "        0.4529, 0.4532, 0.4541, 0.4555, 0.4574, 0.4598, 0.4627, 0.4659, 0.4693,\n",
      "        0.4731, 0.4769, 0.4809, 0.4849, 0.4887, 0.4923, 0.4958, 0.4990, 0.5021,\n",
      "        0.5050, 0.5078, 0.5106, 0.5135, 0.5165, 0.5196, 0.5229, 0.5261, 0.5292,\n",
      "        0.5321, 0.5344, 0.5364, 0.5377, 0.5385, 0.5387, 0.5386, 0.5380, 0.5372,\n",
      "        0.5362, 0.5349, 0.5332, 0.5313, 0.5290, 0.5266, 0.5238, 0.5210, 0.5180,\n",
      "        0.5147, 0.5112, 0.5075, 0.5035, 0.4994, 0.4950, 0.4906, 0.4864, 0.4824,\n",
      "        0.4788, 0.4757, 0.4730, 0.4708, 0.4691, 0.4678, 0.4666, 0.4654, 0.4643,\n",
      "        0.4631, 0.4620, 0.4608, 0.4599, 0.4592, 0.4590, 0.4592, 0.4599, 0.4612,\n",
      "        0.4630, 0.4653, 0.4681, 0.4714, 0.4750, 0.4789, 0.4830, 0.4874, 0.4919,\n",
      "        0.4963, 0.5006, 0.5046, 0.5083, 0.5118, 0.5150, 0.5179, 0.5207, 0.5236,\n",
      "        0.5265, 0.5295, 0.5326, 0.5357, 0.5389, 0.5420, 0.5448, 0.5472, 0.5492,\n",
      "        0.5505, 0.5513, 0.5516, 0.5514, 0.5506, 0.5493, 0.5477, 0.5457, 0.5434,\n",
      "        0.5409, 0.5382, 0.5353, 0.5324, 0.5293, 0.5261, 0.5228, 0.5194, 0.5158,\n",
      "        0.5121, 0.5082, 0.5042, 0.5002, 0.4961, 0.4922, 0.4886, 0.4854, 0.4828,\n",
      "        0.4806, 0.4787, 0.4773, 0.4760, 0.4747, 0.4734, 0.4720, 0.4705, 0.4691,\n",
      "        0.4678, 0.4665, 0.4655, 0.4648, 0.4644, 0.4644, 0.4649, 0.4657, 0.4670,\n",
      "        0.4688, 0.4709, 0.4735, 0.4764, 0.4796, 0.4829, 0.4864, 0.4898, 0.4930,\n",
      "        0.4961, 0.4988, 0.5011, 0.5030, 0.5045, 0.5057, 0.5067, 0.5077, 0.5089,\n",
      "        0.5103, 0.5118, 0.5135, 0.5152, 0.5168, 0.5183, 0.5197, 0.5208, 0.5216,\n",
      "        0.5222, 0.5226, 0.5226, 0.5223, 0.5218, 0.5212, 0.5203, 0.5194, 0.5184,\n",
      "        0.5174, 0.5164, 0.5153, 0.5142, 0.5128, 0.5112, 0.5093, 0.5072, 0.5047,\n",
      "        0.5019, 0.4988, 0.4955, 0.4924, 0.4894, 0.4866, 0.4844, 0.4825, 0.4809,\n",
      "        0.4796, 0.4785, 0.4774, 0.4763, 0.4751, 0.4739, 0.4725, 0.4713, 0.4701,\n",
      "        0.4692, 0.4686, 0.4682, 0.4681, 0.4682, 0.4687, 0.4694, 0.4705, 0.4719,\n",
      "        0.4737, 0.4758, 0.4783, 0.4809, 0.4838, 0.4868, 0.4896, 0.4923, 0.4947,\n",
      "        0.4968, 0.4988, 0.5007, 0.5025, 0.5045, 0.5066, 0.5090, 0.5117, 0.5146,\n",
      "        0.5177, 0.5208, 0.5238, 0.5267, 0.5294, 0.5318, 0.5339, 0.5356, 0.5370,\n",
      "        0.5380, 0.5387, 0.5391, 0.5391, 0.5388, 0.5382, 0.5374, 0.5365, 0.5354,\n",
      "        0.5343, 0.5330, 0.5314, 0.5296, 0.5273, 0.5246, 0.5215, 0.5180, 0.5144,\n",
      "        0.5107, 0.5072, 0.5039, 0.5009, 0.4981, 0.4956, 0.4933, 0.4911, 0.4888,\n",
      "        0.4864, 0.4839, 0.4813, 0.4787, 0.4759, 0.4735, 0.4711, 0.4690, 0.4672,\n",
      "        0.4656, 0.4644, 0.4636, 0.4630, 0.4628, 0.4631, 0.4639, 0.4652, 0.4672,\n",
      "        0.4697, 0.4727, 0.4759, 0.4793, 0.4827, 0.4859, 0.4889, 0.4916, 0.4943,\n",
      "        0.4969, 0.4995, 0.5021, 0.5049, 0.5078, 0.5108, 0.5140, 0.5171, 0.5204,\n",
      "        0.5235, 0.5267, 0.5297, 0.5323, 0.5347, 0.5369, 0.5386, 0.5399, 0.5408,\n",
      "        0.5412, 0.5414, 0.5413, 0.5410, 0.5405, 0.5398, 0.5390, 0.5378, 0.5362,\n",
      "        0.5342, 0.5317, 0.5287, 0.5249, 0.5207, 0.5161, 0.5112, 0.5062, 0.5013,\n",
      "        0.4967, 0.4924, 0.4885, 0.4849, 0.4815, 0.4784, 0.4754, 0.4725, 0.4697,\n",
      "        0.4670, 0.4645, 0.4623, 0.4603, 0.4585, 0.4569, 0.4556, 0.4545, 0.4538,\n",
      "        0.4535, 0.4536, 0.4542, 0.4552, 0.4569, 0.4591, 0.4617, 0.4647, 0.4681,\n",
      "        0.4715, 0.4752, 0.4787, 0.4820, 0.4851, 0.4879, 0.4906, 0.4931, 0.4956,\n",
      "        0.4981, 0.5006, 0.5034, 0.5063, 0.5094, 0.5125, 0.5154, 0.5182, 0.5209]), shape: torch.Size([882])\n",
      "\n",
      "compress or limit:\n",
      "1.0, shape: torch.Size([])\n",
      "\n",
      "peak reduction:\n",
      "0.0, shape: torch.Size([])\n",
      "\n",
      "target waveform:\n",
      "tensor([0.4558, 0.4544, 0.4532, 0.4523, 0.4518, 0.4514, 0.4513, 0.4513, 0.4517,\n",
      "        0.4523, 0.4533, 0.4546, 0.4563, 0.4583, 0.4606, 0.4633, 0.4663, 0.4698,\n",
      "        0.4736, 0.4779, 0.4825, 0.4874, 0.4924, 0.4972, 0.5018, 0.5059, 0.5097,\n",
      "        0.5128, 0.5156, 0.5180, 0.5201, 0.5221, 0.5241, 0.5261, 0.5279, 0.5298,\n",
      "        0.5315, 0.5334, 0.5353, 0.5371, 0.5388, 0.5402, 0.5413, 0.5418, 0.5416,\n",
      "        0.5407, 0.5391, 0.5369, 0.5341, 0.5310, 0.5276, 0.5242, 0.5208, 0.5176,\n",
      "        0.5145, 0.5117, 0.5090, 0.5063, 0.5034, 0.5005, 0.4972, 0.4939, 0.4905,\n",
      "        0.4871, 0.4838, 0.4808, 0.4782, 0.4761, 0.4743, 0.4730, 0.4718, 0.4711,\n",
      "        0.4705, 0.4698, 0.4695, 0.4693, 0.4695, 0.4698, 0.4702, 0.4708, 0.4716,\n",
      "        0.4726, 0.4737, 0.4749, 0.4765, 0.4785, 0.4808, 0.4836, 0.4869, 0.4905,\n",
      "        0.4945, 0.4985, 0.5026, 0.5066, 0.5103, 0.5136, 0.5166, 0.5193, 0.5215,\n",
      "        0.5235, 0.5252, 0.5266, 0.5279, 0.5290, 0.5299, 0.5308, 0.5316, 0.5325,\n",
      "        0.5334, 0.5344, 0.5354, 0.5362, 0.5367, 0.5369, 0.5366, 0.5357, 0.5344,\n",
      "        0.5325, 0.5301, 0.5275, 0.5249, 0.5222, 0.5196, 0.5170, 0.5146, 0.5122,\n",
      "        0.5098, 0.5073, 0.5048, 0.5020, 0.4990, 0.4957, 0.4925, 0.4892, 0.4860,\n",
      "        0.4830, 0.4801, 0.4776, 0.4754, 0.4735, 0.4719, 0.4706, 0.4696, 0.4689,\n",
      "        0.4684, 0.4681, 0.4680, 0.4681, 0.4684, 0.4688, 0.4692, 0.4697, 0.4703,\n",
      "        0.4712, 0.4722, 0.4736, 0.4752, 0.4774, 0.4800, 0.4829, 0.4860, 0.4892,\n",
      "        0.4922, 0.4951, 0.4976, 0.4999, 0.5020, 0.5038, 0.5055, 0.5068, 0.5082,\n",
      "        0.5094, 0.5107, 0.5121, 0.5135, 0.5152, 0.5172, 0.5192, 0.5214, 0.5237,\n",
      "        0.5258, 0.5278, 0.5295, 0.5308, 0.5316, 0.5318, 0.5313, 0.5305, 0.5291,\n",
      "        0.5273, 0.5252, 0.5229, 0.5206, 0.5183, 0.5161, 0.5138, 0.5114, 0.5088,\n",
      "        0.5059, 0.5028, 0.4995, 0.4959, 0.4922, 0.4886, 0.4852, 0.4819, 0.4788,\n",
      "        0.4759, 0.4733, 0.4709, 0.4687, 0.4668, 0.4651, 0.4636, 0.4623, 0.4612,\n",
      "        0.4601, 0.4593, 0.4585, 0.4579, 0.4573, 0.4570, 0.4569, 0.4571, 0.4578,\n",
      "        0.4589, 0.4607, 0.4631, 0.4661, 0.4698, 0.4738, 0.4780, 0.4824, 0.4867,\n",
      "        0.4909, 0.4950, 0.4988, 0.5025, 0.5059, 0.5093, 0.5125, 0.5155, 0.5184,\n",
      "        0.5213, 0.5241, 0.5269, 0.5298, 0.5326, 0.5356, 0.5386, 0.5415, 0.5442,\n",
      "        0.5466, 0.5484, 0.5496, 0.5502, 0.5502, 0.5496, 0.5485, 0.5469, 0.5450,\n",
      "        0.5431, 0.5410, 0.5390, 0.5369, 0.5346, 0.5321, 0.5293, 0.5261, 0.5225,\n",
      "        0.5186, 0.5145, 0.5102, 0.5058, 0.5013, 0.4969, 0.4925, 0.4885, 0.4847,\n",
      "        0.4810, 0.4777, 0.4749, 0.4723, 0.4702, 0.4685, 0.4672, 0.4662, 0.4654,\n",
      "        0.4647, 0.4641, 0.4635, 0.4631, 0.4628, 0.4630, 0.4638, 0.4651, 0.4670,\n",
      "        0.4696, 0.4727, 0.4762, 0.4800, 0.4839, 0.4878, 0.4915, 0.4953, 0.4988,\n",
      "        0.5020, 0.5050, 0.5077, 0.5101, 0.5122, 0.5142, 0.5160, 0.5177, 0.5193,\n",
      "        0.5212, 0.5230, 0.5249, 0.5269, 0.5290, 0.5309, 0.5326, 0.5339, 0.5346,\n",
      "        0.5347, 0.5341, 0.5327, 0.5307, 0.5282, 0.5255, 0.5225, 0.5196, 0.5166,\n",
      "        0.5135, 0.5104, 0.5073, 0.5042, 0.5009, 0.4976, 0.4943, 0.4911, 0.4878,\n",
      "        0.4845, 0.4813, 0.4782, 0.4752, 0.4724, 0.4698, 0.4675, 0.4656, 0.4641,\n",
      "        0.4630, 0.4623, 0.4619, 0.4618, 0.4621, 0.4624, 0.4628, 0.4631, 0.4634,\n",
      "        0.4636, 0.4641, 0.4647, 0.4655, 0.4668, 0.4686, 0.4710, 0.4738, 0.4771,\n",
      "        0.4807, 0.4844, 0.4882, 0.4921, 0.4959, 0.4997, 0.5032, 0.5066, 0.5096,\n",
      "        0.5124, 0.5147, 0.5167, 0.5184, 0.5198, 0.5211, 0.5222, 0.5234, 0.5246,\n",
      "        0.5260, 0.5275, 0.5290, 0.5305, 0.5319, 0.5330, 0.5339, 0.5343, 0.5344,\n",
      "        0.5338, 0.5329, 0.5317, 0.5301, 0.5285, 0.5268, 0.5249, 0.5231, 0.5211,\n",
      "        0.5191, 0.5170, 0.5148, 0.5125, 0.5099, 0.5071, 0.5043, 0.5013, 0.4983,\n",
      "        0.4952, 0.4921, 0.4891, 0.4861, 0.4832, 0.4807, 0.4786, 0.4768, 0.4756,\n",
      "        0.4748, 0.4742, 0.4738, 0.4735, 0.4732, 0.4729, 0.4726, 0.4723, 0.4721,\n",
      "        0.4721, 0.4723, 0.4729, 0.4740, 0.4755, 0.4774, 0.4797, 0.4822, 0.4849,\n",
      "        0.4880, 0.4910, 0.4939, 0.4967, 0.4994, 0.5019, 0.5044, 0.5066, 0.5086,\n",
      "        0.5105, 0.5122, 0.5138, 0.5153, 0.5169, 0.5187, 0.5206, 0.5228, 0.5252,\n",
      "        0.5277, 0.5302, 0.5325, 0.5345, 0.5360, 0.5371, 0.5378, 0.5380, 0.5377,\n",
      "        0.5370, 0.5360, 0.5347, 0.5332, 0.5316, 0.5298, 0.5278, 0.5256, 0.5233,\n",
      "        0.5207, 0.5178, 0.5149, 0.5118, 0.5087, 0.5054, 0.5020, 0.4987, 0.4954,\n",
      "        0.4920, 0.4888, 0.4857, 0.4829, 0.4802, 0.4779, 0.4758, 0.4740, 0.4723,\n",
      "        0.4706, 0.4688, 0.4668, 0.4646, 0.4624, 0.4602, 0.4582, 0.4566, 0.4555,\n",
      "        0.4550, 0.4550, 0.4556, 0.4570, 0.4586, 0.4608, 0.4635, 0.4664, 0.4697,\n",
      "        0.4732, 0.4769, 0.4807, 0.4846, 0.4883, 0.4918, 0.4953, 0.4985, 0.5015,\n",
      "        0.5043, 0.5070, 0.5097, 0.5124, 0.5152, 0.5181, 0.5211, 0.5243, 0.5273,\n",
      "        0.5301, 0.5325, 0.5345, 0.5360, 0.5369, 0.5373, 0.5372, 0.5368, 0.5361,\n",
      "        0.5351, 0.5339, 0.5324, 0.5306, 0.5285, 0.5261, 0.5236, 0.5208, 0.5180,\n",
      "        0.5150, 0.5118, 0.5083, 0.5046, 0.5006, 0.4965, 0.4923, 0.4881, 0.4842,\n",
      "        0.4806, 0.4775, 0.4748, 0.4725, 0.4707, 0.4694, 0.4682, 0.4672, 0.4661,\n",
      "        0.4651, 0.4640, 0.4630, 0.4620, 0.4613, 0.4609, 0.4610, 0.4616, 0.4626,\n",
      "        0.4642, 0.4663, 0.4688, 0.4718, 0.4752, 0.4788, 0.4827, 0.4869, 0.4911,\n",
      "        0.4955, 0.4997, 0.5036, 0.5073, 0.5106, 0.5138, 0.5166, 0.5194, 0.5221,\n",
      "        0.5248, 0.5276, 0.5305, 0.5334, 0.5365, 0.5394, 0.5422, 0.5446, 0.5467,\n",
      "        0.5481, 0.5490, 0.5494, 0.5493, 0.5487, 0.5476, 0.5461, 0.5442, 0.5421,\n",
      "        0.5397, 0.5371, 0.5344, 0.5316, 0.5286, 0.5255, 0.5224, 0.5192, 0.5159,\n",
      "        0.5123, 0.5086, 0.5047, 0.5009, 0.4970, 0.4932, 0.4896, 0.4864, 0.4837,\n",
      "        0.4815, 0.4796, 0.4782, 0.4769, 0.4756, 0.4745, 0.4732, 0.4719, 0.4705,\n",
      "        0.4692, 0.4680, 0.4670, 0.4663, 0.4658, 0.4657, 0.4660, 0.4667, 0.4677,\n",
      "        0.4693, 0.4714, 0.4737, 0.4763, 0.4794, 0.4825, 0.4858, 0.4891, 0.4924,\n",
      "        0.4953, 0.4981, 0.5004, 0.5025, 0.5040, 0.5052, 0.5062, 0.5072, 0.5082,\n",
      "        0.5095, 0.5109, 0.5124, 0.5140, 0.5156, 0.5171, 0.5184, 0.5196, 0.5205,\n",
      "        0.5211, 0.5215, 0.5216, 0.5214, 0.5210, 0.5204, 0.5197, 0.5187, 0.5178,\n",
      "        0.5168, 0.5158, 0.5148, 0.5137, 0.5125, 0.5111, 0.5094, 0.5074, 0.5052,\n",
      "        0.5025, 0.4997, 0.4966, 0.4935, 0.4906, 0.4879, 0.4855, 0.4835, 0.4819,\n",
      "        0.4807, 0.4796, 0.4786, 0.4775, 0.4765, 0.4753, 0.4741, 0.4729, 0.4717,\n",
      "        0.4708, 0.4701, 0.4697, 0.4695, 0.4696, 0.4700, 0.4706, 0.4716, 0.4728,\n",
      "        0.4744, 0.4764, 0.4786, 0.4811, 0.4838, 0.4867, 0.4894, 0.4922, 0.4946,\n",
      "        0.4967, 0.4986, 0.5004, 0.5022, 0.5041, 0.5060, 0.5082, 0.5107, 0.5134,\n",
      "        0.5163, 0.5192, 0.5221, 0.5249, 0.5275, 0.5299, 0.5321, 0.5338, 0.5352,\n",
      "        0.5363, 0.5370, 0.5375, 0.5375, 0.5373, 0.5368, 0.5360, 0.5352, 0.5342,\n",
      "        0.5331, 0.5319, 0.5304, 0.5287, 0.5267, 0.5242, 0.5214, 0.5181, 0.5147,\n",
      "        0.5112, 0.5077, 0.5045, 0.5014, 0.4987, 0.4962, 0.4939, 0.4918, 0.4896,\n",
      "        0.4874, 0.4851, 0.4826, 0.4802, 0.4775, 0.4750, 0.4729, 0.4707, 0.4689,\n",
      "        0.4673, 0.4661, 0.4652, 0.4646, 0.4643, 0.4645, 0.4651, 0.4661, 0.4679,\n",
      "        0.4701, 0.4729, 0.4759, 0.4792, 0.4824, 0.4856, 0.4886, 0.4914, 0.4939,\n",
      "        0.4965, 0.4989, 0.5014, 0.5040, 0.5068, 0.5097, 0.5127, 0.5156, 0.5187,\n",
      "        0.5217, 0.5247, 0.5276, 0.5302, 0.5326, 0.5346, 0.5365, 0.5378, 0.5388,\n",
      "        0.5393, 0.5395, 0.5394, 0.5392, 0.5387, 0.5382, 0.5373, 0.5362, 0.5349,\n",
      "        0.5331, 0.5309, 0.5281, 0.5248, 0.5209, 0.5165, 0.5119, 0.5071, 0.5023,\n",
      "        0.4979, 0.4935, 0.4897, 0.4861, 0.4828, 0.4798, 0.4769, 0.4741, 0.4714,\n",
      "        0.4689, 0.4664, 0.4642, 0.4623, 0.4605, 0.4589, 0.4576, 0.4566, 0.4558,\n",
      "        0.4554, 0.4554, 0.4558, 0.4567, 0.4581, 0.4601, 0.4625, 0.4653, 0.4684,\n",
      "        0.4717, 0.4752, 0.4787, 0.4820, 0.4851, 0.4879, 0.4905, 0.4930, 0.4954,\n",
      "        0.4977, 0.5002, 0.5027, 0.5055, 0.5084, 0.5114, 0.5142, 0.5169, 0.5195]), shape: torch.Size([882])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(input_waveform, cl, pr), target_waveform = train_dataset.__getitem__(400)\n",
    "\n",
    "print(f\"input waveform:\\n{input_waveform}, shape: {input_waveform.shape}\\n\")\n",
    "print(f\"compress or limit:\\n{cl}, shape: {cl.shape}\\n\")\n",
    "print(f\"peak reduction:\\n{pr}, shape: {pr.shape}\\n\")\n",
    "print(f\"target waveform:\\n{target_waveform}, shape: {target_waveform.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider an MLP that will have a \"bottleneck\" (like a trivial autoencoder) to make our PoC.\n",
    "\n",
    "Challenges of Neural Modelling made explicit:\n",
    "- It is very difficult to use \"large\" architectures like LSTM / Transformers in this setup, because with an input size of say 882 samples (which with a SR of 44.1kHz represents 0.02 seconds of music), a fairly standard LSTM with hidden size 64 and embedding size of 128 for the compressor parameters (quite big to be fair), with an MLP decoder (4 layers that reduce the dimensions of the flattened LSTM output + embedded compressor parameters back to the correct number of samples i.e 882). This gave me a model with 235 million parameters. 4 times bigger than BERT (think of it like this, RoBERTa has a sequence length of 512, our \"sequence length\" is effectively 882 if we throw the 0.02s of audio into the LSTM). This 0.02s may be insufficient to capture the dynamics of the compressor depending on the attack and release times (which may exceed 20s) - making the modelling of a time dependent effect like a compressor very difficult.\n",
    "\n",
    "- Needless to say, running real time inference for high fidelity audio for a model which has a parameter count in the millions, in python, to fill an audio buffer of your DAW, it seems impossible. Hence the challenge of neural modelling, and why companies that propose \"neural\" inspired VSTs are using a very small network (effectively fancy LR) to model circuits, and not audio - greatly reducing the dimensions.\n",
    "\n",
    "- DSP approaches much better suited for this task.\n",
    "\n",
    "Possible solutions\n",
    "- Downsample audio for inference, use low latency upsampler to upsample the output (these models do exist e.g the one from Facebook using RVQ)\n",
    "\n",
    "- Do not use LSTM / sequential modelling to model an inidivdual sequence of 882 samples, if using sequential modelling, use it to treat a sequence of samples so that instead of the effective sequence length being 882, it would be, sy 16 (if you treat 16 clips of 882 samples) - this can reduce the parameter count and still perhaps bring some \"temporal\" modelling benefits to the model\n",
    "\n",
    "Notes:\n",
    "- The training loop below converges very quickly, after basically 25 batches (of an epoch of 780 batches) - will have to make sure there's no error in the training and that the inference can produce realistic audio but this is interesting as it means that perhaps a small amount of data is needed to do this type of modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 797.599853515625\n",
      "EPOCH 1 | Batch 1/798 | Time: 0.012181365489959716 mins | Loss: 0.23357173800468445 | Batches Left: 797\n",
      "EPOCH 1 | Batch 2/798 | Time: 0.000499268372853597 mins | Loss: 0.20942844450473785 | Batches Left: 796\n",
      "EPOCH 1 | Batch 3/798 | Time: 0.0005411823590596517 mins | Loss: 0.1717255860567093 | Batches Left: 795\n",
      "EPOCH 1 | Batch 4/798 | Time: 0.0005015015602111816 mins | Loss: 0.13751059770584106 | Batches Left: 794\n",
      "EPOCH 1 | Batch 5/798 | Time: 0.0005005836486816406 mins | Loss: 0.13605394959449768 | Batches Left: 793\n",
      "EPOCH 1 | Batch 6/798 | Time: 0.0005006194114685059 mins | Loss: 0.1254543960094452 | Batches Left: 792\n",
      "EPOCH 1 | Batch 7/798 | Time: 0.0005041162172953287 mins | Loss: 0.10199355334043503 | Batches Left: 791\n",
      "EPOCH 1 | Batch 8/798 | Time: 0.0005008300145467122 mins | Loss: 0.08879490196704865 | Batches Left: 790\n",
      "EPOCH 1 | Batch 9/798 | Time: 0.0005022366841634115 mins | Loss: 0.08615609258413315 | Batches Left: 789\n",
      "EPOCH 1 | Batch 10/798 | Time: 0.0005029479662577312 mins | Loss: 0.08567718416452408 | Batches Left: 788\n",
      "EPOCH 1 | Batch 11/798 | Time: 0.0004956841468811036 mins | Loss: 0.08350004255771637 | Batches Left: 787\n",
      "EPOCH 1 | Batch 12/798 | Time: 0.0004945834477742513 mins | Loss: 0.08103565871715546 | Batches Left: 786\n",
      "EPOCH 1 | Batch 13/798 | Time: 0.0004959305127461752 mins | Loss: 0.08069122582674026 | Batches Left: 785\n",
      "EPOCH 1 | Batch 14/798 | Time: 0.0004910826683044434 mins | Loss: 0.08027680963277817 | Batches Left: 784\n",
      "EPOCH 1 | Batch 15/798 | Time: 0.0005092501640319824 mins | Loss: 0.0787467360496521 | Batches Left: 783\n",
      "EPOCH 1 | Batch 16/798 | Time: 0.0005214492479960124 mins | Loss: 0.07585915923118591 | Batches Left: 782\n",
      "EPOCH 1 | Batch 17/798 | Time: 0.0004859805107116699 mins | Loss: 0.0738658756017685 | Batches Left: 781\n",
      "EPOCH 1 | Batch 18/798 | Time: 0.0004914323488871257 mins | Loss: 0.07247508317232132 | Batches Left: 780\n",
      "EPOCH 1 | Batch 19/798 | Time: 0.00048828125 mins | Loss: 0.07137356698513031 | Batches Left: 779\n",
      "EPOCH 1 | Batch 20/798 | Time: 0.00047624905904134114 mins | Loss: 0.07000597566366196 | Batches Left: 778\n",
      "EPOCH 1 | Batch 21/798 | Time: 0.0005082130432128906 mins | Loss: 0.06872621923685074 | Batches Left: 777\n",
      "EPOCH 1 | Batch 22/798 | Time: 0.0004868666330973307 mins | Loss: 0.06772587448358536 | Batches Left: 776\n",
      "EPOCH 1 | Batch 23/798 | Time: 0.0004937171936035157 mins | Loss: 0.06721365451812744 | Batches Left: 775\n",
      "EPOCH 1 | Batch 24/798 | Time: 0.0005076328913370768 mins | Loss: 0.06609562784433365 | Batches Left: 774\n",
      "EPOCH 1 | Batch 25/798 | Time: 0.0004812479019165039 mins | Loss: 0.06500906497240067 | Batches Left: 773\n",
      "EPOCH 1 | Batch 26/798 | Time: 0.0005837003389994303 mins | Loss: 0.06390997022390366 | Batches Left: 772\n",
      "EPOCH 1 | Batch 27/798 | Time: 0.0005446155865987142 mins | Loss: 0.06360204517841339 | Batches Left: 771\n",
      "EPOCH 1 | Batch 28/798 | Time: 0.0005172967910766601 mins | Loss: 0.06257353723049164 | Batches Left: 770\n",
      "EPOCH 1 | Batch 29/798 | Time: 0.0005281488100687663 mins | Loss: 0.06173602491617203 | Batches Left: 769\n",
      "EPOCH 1 | Batch 30/798 | Time: 0.0004992842674255371 mins | Loss: 0.06113794445991516 | Batches Left: 768\n",
      "EPOCH 1 | Batch 31/798 | Time: 0.0005251049995422363 mins | Loss: 0.06076084449887276 | Batches Left: 767\n",
      "EPOCH 1 | Batch 32/798 | Time: 0.0005121827125549316 mins | Loss: 0.06035829335451126 | Batches Left: 766\n",
      "EPOCH 1 | Batch 33/798 | Time: 0.0004916032155354818 mins | Loss: 0.059522997587919235 | Batches Left: 765\n",
      "EPOCH 1 | Batch 34/798 | Time: 0.0005977829297383626 mins | Loss: 0.058928102254867554 | Batches Left: 764\n",
      "EPOCH 1 | Batch 35/798 | Time: 0.0004966139793395996 mins | Loss: 0.058878667652606964 | Batches Left: 763\n",
      "EPOCH 1 | Batch 36/798 | Time: 0.0004839340845743815 mins | Loss: 0.05856763571500778 | Batches Left: 762\n",
      "EPOCH 1 | Batch 37/798 | Time: 0.0004893898963928223 mins | Loss: 0.05827363207936287 | Batches Left: 761\n",
      "EPOCH 1 | Batch 38/798 | Time: 0.0004893978436787923 mins | Loss: 0.05813371390104294 | Batches Left: 760\n",
      "EPOCH 1 | Batch 39/798 | Time: 0.0004920283953348796 mins | Loss: 0.05806947499513626 | Batches Left: 759\n",
      "EPOCH 1 | Batch 40/798 | Time: 0.0005093495051066081 mins | Loss: 0.05767826735973358 | Batches Left: 758\n",
      "EPOCH 1 | Batch 41/798 | Time: 0.0005174160003662109 mins | Loss: 0.057715609669685364 | Batches Left: 757\n",
      "EPOCH 1 | Batch 42/798 | Time: 0.0005095322926839192 mins | Loss: 0.05738644301891327 | Batches Left: 756\n",
      "EPOCH 1 | Batch 43/798 | Time: 0.0005438804626464843 mins | Loss: 0.05722418799996376 | Batches Left: 755\n",
      "EPOCH 1 | Batch 44/798 | Time: 0.0004919171333312988 mins | Loss: 0.05705138295888901 | Batches Left: 754\n",
      "EPOCH 1 | Batch 45/798 | Time: 0.0005264004071553548 mins | Loss: 0.05682840198278427 | Batches Left: 753\n",
      "EPOCH 1 | Batch 46/798 | Time: 0.00048781633377075194 mins | Loss: 0.05675893276929855 | Batches Left: 752\n",
      "EPOCH 1 | Batch 47/798 | Time: 0.0005541364351908366 mins | Loss: 0.056594450026750565 | Batches Left: 751\n",
      "EPOCH 1 | Batch 48/798 | Time: 0.0005176544189453125 mins | Loss: 0.05636376887559891 | Batches Left: 750\n",
      "EPOCH 1 | Batch 49/798 | Time: 0.0005549987157185873 mins | Loss: 0.05616714432835579 | Batches Left: 749\n",
      "EPOCH 1 | Batch 50/798 | Time: 0.0004962801933288575 mins | Loss: 0.056144796311855316 | Batches Left: 748\n",
      "EPOCH 1 | Batch 51/798 | Time: 0.000489350159962972 mins | Loss: 0.05597786232829094 | Batches Left: 747\n",
      "EPOCH 1 | Batch 52/798 | Time: 0.0004956364631652832 mins | Loss: 0.05588066950440407 | Batches Left: 746\n",
      "EPOCH 1 | Batch 53/798 | Time: 0.0005606333414713542 mins | Loss: 0.05593156814575195 | Batches Left: 745\n",
      "EPOCH 1 | Batch 54/798 | Time: 0.000511467456817627 mins | Loss: 0.05601087212562561 | Batches Left: 744\n",
      "EPOCH 1 | Batch 55/798 | Time: 0.0004939834276835123 mins | Loss: 0.05552307143807411 | Batches Left: 743\n",
      "EPOCH 1 | Batch 56/798 | Time: 0.0005255778630574544 mins | Loss: 0.05557074770331383 | Batches Left: 742\n",
      "EPOCH 1 | Batch 57/798 | Time: 0.0005044698715209961 mins | Loss: 0.055499106645584106 | Batches Left: 741\n",
      "EPOCH 1 | Batch 58/798 | Time: 0.0005185842514038086 mins | Loss: 0.055632151663303375 | Batches Left: 740\n",
      "EPOCH 1 | Batch 59/798 | Time: 0.0005612492561340332 mins | Loss: 0.05533980578184128 | Batches Left: 739\n",
      "EPOCH 1 | Batch 60/798 | Time: 0.0005038817723592123 mins | Loss: 0.055456023663282394 | Batches Left: 738\n",
      "EPOCH 1 | Batch 61/798 | Time: 0.0005669156710306803 mins | Loss: 0.055399466305971146 | Batches Left: 737\n",
      "EPOCH 1 | Batch 62/798 | Time: 0.0005231976509094238 mins | Loss: 0.05540314316749573 | Batches Left: 736\n",
      "EPOCH 1 | Batch 63/798 | Time: 0.0006338993708292644 mins | Loss: 0.05540915206074715 | Batches Left: 735\n",
      "EPOCH 1 | Batch 64/798 | Time: 0.0005834142367045085 mins | Loss: 0.05544519051909447 | Batches Left: 734\n",
      "EPOCH 1 | Batch 65/798 | Time: 0.0005144516626993816 mins | Loss: 0.05532795935869217 | Batches Left: 733\n",
      "EPOCH 1 | Batch 66/798 | Time: 0.0004946827888488769 mins | Loss: 0.055101245641708374 | Batches Left: 732\n",
      "EPOCH 1 | Batch 67/798 | Time: 0.000502769152323405 mins | Loss: 0.05497771501541138 | Batches Left: 731\n",
      "EPOCH 1 | Batch 68/798 | Time: 0.00050506591796875 mins | Loss: 0.055085405707359314 | Batches Left: 730\n",
      "EPOCH 1 | Batch 69/798 | Time: 0.0005116621653238932 mins | Loss: 0.0549493171274662 | Batches Left: 729\n",
      "EPOCH 1 | Batch 70/798 | Time: 0.0005269845326741537 mins | Loss: 0.0550987608730793 | Batches Left: 728\n",
      "EPOCH 1 | Batch 71/798 | Time: 0.0005416353543599447 mins | Loss: 0.05479874834418297 | Batches Left: 727\n",
      "EPOCH 1 | Batch 72/798 | Time: 0.0005677382151285808 mins | Loss: 0.05497055873274803 | Batches Left: 726\n",
      "EPOCH 1 | Batch 73/798 | Time: 0.0005268335342407226 mins | Loss: 0.05494075268507004 | Batches Left: 725\n",
      "EPOCH 1 | Batch 74/798 | Time: 0.00051116943359375 mins | Loss: 0.05513303354382515 | Batches Left: 724\n",
      "EPOCH 1 | Batch 75/798 | Time: 0.0005468010902404785 mins | Loss: 0.05495113506913185 | Batches Left: 723\n",
      "EPOCH 1 | Batch 76/798 | Time: 0.0005045851071675618 mins | Loss: 0.05507276952266693 | Batches Left: 722\n",
      "EPOCH 1 | Batch 77/798 | Time: 0.0005508025487263997 mins | Loss: 0.05500319227576256 | Batches Left: 721\n",
      "EPOCH 1 | Batch 78/798 | Time: 0.0005101641019185384 mins | Loss: 0.05503064766526222 | Batches Left: 720\n",
      "EPOCH 1 | Batch 79/798 | Time: 0.0005259990692138671 mins | Loss: 0.0549885593354702 | Batches Left: 719\n",
      "EPOCH 1 | Batch 80/798 | Time: 0.0005374511082967122 mins | Loss: 0.05502310022711754 | Batches Left: 718\n",
      "EPOCH 1 | Batch 81/798 | Time: 0.0004959146181742351 mins | Loss: 0.054936233907938004 | Batches Left: 717\n",
      "EPOCH 1 | Batch 82/798 | Time: 0.0005155682563781738 mins | Loss: 0.05487839877605438 | Batches Left: 716\n",
      "EPOCH 1 | Batch 83/798 | Time: 0.000530083974202474 mins | Loss: 0.05486438795924187 | Batches Left: 715\n",
      "EPOCH 1 | Batch 84/798 | Time: 0.0005002498626708984 mins | Loss: 0.05486346408724785 | Batches Left: 714\n",
      "EPOCH 1 | Batch 85/798 | Time: 0.0005046486854553223 mins | Loss: 0.05510552600026131 | Batches Left: 713\n",
      "EPOCH 1 | Batch 86/798 | Time: 0.000487665335337321 mins | Loss: 0.05487511679530144 | Batches Left: 712\n",
      "EPOCH 1 | Batch 87/798 | Time: 0.0005176822344462077 mins | Loss: 0.05507025495171547 | Batches Left: 711\n",
      "EPOCH 1 | Batch 88/798 | Time: 0.0005841334660847982 mins | Loss: 0.05491608753800392 | Batches Left: 710\n",
      "EPOCH 1 | Batch 89/798 | Time: 0.00050811767578125 mins | Loss: 0.055151794105768204 | Batches Left: 709\n",
      "EPOCH 1 | Batch 90/798 | Time: 0.0005165298779805501 mins | Loss: 0.054595354944467545 | Batches Left: 708\n",
      "EPOCH 1 | Batch 91/798 | Time: 0.0005257685979207356 mins | Loss: 0.0548819974064827 | Batches Left: 707\n",
      "EPOCH 1 | Batch 92/798 | Time: 0.0005951325098673502 mins | Loss: 0.05477912351489067 | Batches Left: 706\n",
      "EPOCH 1 | Batch 93/798 | Time: 0.0005155642827351888 mins | Loss: 0.05470527336001396 | Batches Left: 705\n",
      "EPOCH 1 | Batch 94/798 | Time: 0.0005494991938273112 mins | Loss: 0.054685793817043304 | Batches Left: 704\n",
      "EPOCH 1 | Batch 95/798 | Time: 0.0005830168724060058 mins | Loss: 0.05454454943537712 | Batches Left: 703\n",
      "EPOCH 1 | Batch 96/798 | Time: 0.0005053480466206869 mins | Loss: 0.05453541502356529 | Batches Left: 702\n",
      "EPOCH 1 | Batch 97/798 | Time: 0.0005699475606282552 mins | Loss: 0.05454397201538086 | Batches Left: 701\n",
      "EPOCH 1 | Batch 98/798 | Time: 0.0005905628204345703 mins | Loss: 0.054675884544849396 | Batches Left: 700\n",
      "EPOCH 1 | Batch 99/798 | Time: 0.000497130552927653 mins | Loss: 0.054756078869104385 | Batches Left: 699\n",
      "EPOCH 1 | Batch 100/798 | Time: 0.0005031665166219076 mins | Loss: 0.054581426084041595 | Batches Left: 698\n",
      "EPOCH 1 | Batch 101/798 | Time: 0.0005044182141621908 mins | Loss: 0.05477409437298775 | Batches Left: 697\n",
      "EPOCH 1 | Batch 102/798 | Time: 0.0004936655362447103 mins | Loss: 0.05447894707322121 | Batches Left: 696\n",
      "EPOCH 1 | Batch 103/798 | Time: 0.0004981676737467448 mins | Loss: 0.054657917469739914 | Batches Left: 695\n",
      "EPOCH 1 | Batch 104/798 | Time: 0.0006066322326660156 mins | Loss: 0.05465158075094223 | Batches Left: 694\n",
      "EPOCH 1 | Batch 105/798 | Time: 0.0005108038584391276 mins | Loss: 0.05453826114535332 | Batches Left: 693\n",
      "EPOCH 1 | Batch 106/798 | Time: 0.0005262136459350586 mins | Loss: 0.054479993879795074 | Batches Left: 692\n",
      "EPOCH 1 | Batch 107/798 | Time: 0.0005218029022216797 mins | Loss: 0.054411955177783966 | Batches Left: 691\n",
      "EPOCH 1 | Batch 108/798 | Time: 0.0004996140797932943 mins | Loss: 0.05439396947622299 | Batches Left: 690\n",
      "EPOCH 1 | Batch 109/798 | Time: 0.0004889527956644694 mins | Loss: 0.05426274985074997 | Batches Left: 689\n",
      "EPOCH 1 | Batch 110/798 | Time: 0.0006158351898193359 mins | Loss: 0.054159775376319885 | Batches Left: 688\n",
      "EPOCH 1 | Batch 111/798 | Time: 0.0005059321721394857 mins | Loss: 0.054078154265880585 | Batches Left: 687\n",
      "EPOCH 1 | Batch 112/798 | Time: 0.0005789001782735189 mins | Loss: 0.05419258028268814 | Batches Left: 686\n",
      "EPOCH 1 | Batch 113/798 | Time: 0.0005074024200439453 mins | Loss: 0.05401219427585602 | Batches Left: 685\n",
      "EPOCH 1 | Batch 114/798 | Time: 0.0004954139391581217 mins | Loss: 0.05390756204724312 | Batches Left: 684\n",
      "EPOCH 1 | Batch 115/798 | Time: 0.00048581361770629885 mins | Loss: 0.0541129969060421 | Batches Left: 683\n",
      "EPOCH 1 | Batch 116/798 | Time: 0.0005129853884379069 mins | Loss: 0.05380355939269066 | Batches Left: 682\n",
      "EPOCH 1 | Batch 117/798 | Time: 0.0006084005037943522 mins | Loss: 0.054068032652139664 | Batches Left: 681\n",
      "EPOCH 1 | Batch 118/798 | Time: 0.0005228837331136067 mins | Loss: 0.05419110879302025 | Batches Left: 680\n",
      "EPOCH 1 | Batch 119/798 | Time: 0.0004986683527628581 mins | Loss: 0.0539604090154171 | Batches Left: 679\n",
      "EPOCH 1 | Batch 120/798 | Time: 0.0005503296852111816 mins | Loss: 0.05396386608481407 | Batches Left: 678\n",
      "EPOCH 1 | Batch 121/798 | Time: 0.0004972656567891439 mins | Loss: 0.054022472351789474 | Batches Left: 677\n",
      "EPOCH 1 | Batch 122/798 | Time: 0.00048274993896484374 mins | Loss: 0.05399893969297409 | Batches Left: 676\n",
      "EPOCH 1 | Batch 123/798 | Time: 0.0005191524823506673 mins | Loss: 0.0538516640663147 | Batches Left: 675\n",
      "EPOCH 1 | Batch 124/798 | Time: 0.0004922668139139811 mins | Loss: 0.05391800031065941 | Batches Left: 674\n",
      "EPOCH 1 | Batch 125/798 | Time: 0.0005665977795918782 mins | Loss: 0.0538012832403183 | Batches Left: 673\n",
      "EPOCH 1 | Batch 126/798 | Time: 0.0004895806312561035 mins | Loss: 0.05393088608980179 | Batches Left: 672\n",
      "EPOCH 1 | Batch 127/798 | Time: 0.00047676563262939454 mins | Loss: 0.05395931378006935 | Batches Left: 671\n",
      "EPOCH 1 | Batch 128/798 | Time: 0.0005120356877644856 mins | Loss: 0.05387867987155914 | Batches Left: 670\n",
      "EPOCH 1 | Batch 129/798 | Time: 0.0005116661389668783 mins | Loss: 0.05393654853105545 | Batches Left: 669\n",
      "EPOCH 1 | Batch 130/798 | Time: 0.000664981206258138 mins | Loss: 0.054023124277591705 | Batches Left: 668\n",
      "EPOCH 1 | Batch 131/798 | Time: 0.0006125330924987793 mins | Loss: 0.053761281073093414 | Batches Left: 667\n",
      "EPOCH 1 | Batch 132/798 | Time: 0.0005499482154846192 mins | Loss: 0.053829044103622437 | Batches Left: 666\n",
      "EPOCH 1 | Batch 133/798 | Time: 0.0004911144574483235 mins | Loss: 0.05379178375005722 | Batches Left: 665\n",
      "EPOCH 1 | Batch 134/798 | Time: 0.0004952669143676758 mins | Loss: 0.053699709475040436 | Batches Left: 664\n",
      "EPOCH 1 | Batch 135/798 | Time: 0.0004880984624226888 mins | Loss: 0.05348524823784828 | Batches Left: 663\n",
      "EPOCH 1 | Batch 136/798 | Time: 0.0007438619931538899 mins | Loss: 0.05358343943953514 | Batches Left: 662\n",
      "EPOCH 1 | Batch 137/798 | Time: 0.0006683667500813802 mins | Loss: 0.05355828255414963 | Batches Left: 661\n",
      "EPOCH 1 | Batch 138/798 | Time: 0.0004970351854960124 mins | Loss: 0.05360344052314758 | Batches Left: 660\n",
      "EPOCH 1 | Batch 139/798 | Time: 0.0005763133366902669 mins | Loss: 0.05375133454799652 | Batches Left: 659\n",
      "EPOCH 1 | Batch 140/798 | Time: 0.0005128304163614909 mins | Loss: 0.053861793130636215 | Batches Left: 658\n",
      "EPOCH 1 | Batch 141/798 | Time: 0.0005051016807556153 mins | Loss: 0.053590089082717896 | Batches Left: 657\n",
      "EPOCH 1 | Batch 142/798 | Time: 0.00048540035883585614 mins | Loss: 0.05369983986020088 | Batches Left: 656\n",
      "EPOCH 1 | Batch 143/798 | Time: 0.0005153179168701172 mins | Loss: 0.05374285578727722 | Batches Left: 655\n",
      "EPOCH 1 | Batch 144/798 | Time: 0.0005959669748942057 mins | Loss: 0.05374612286686897 | Batches Left: 654\n",
      "EPOCH 1 | Batch 145/798 | Time: 0.0005555311838785807 mins | Loss: 0.05373669043183327 | Batches Left: 653\n",
      "EPOCH 1 | Batch 146/798 | Time: 0.0005207300186157226 mins | Loss: 0.05346156284213066 | Batches Left: 652\n",
      "EPOCH 1 | Batch 147/798 | Time: 0.0004916826883951823 mins | Loss: 0.053378570824861526 | Batches Left: 651\n",
      "EPOCH 1 | Batch 148/798 | Time: 0.000549916426340739 mins | Loss: 0.053313449025154114 | Batches Left: 650\n",
      "EPOCH 1 | Batch 149/798 | Time: 0.0005047996838887532 mins | Loss: 0.053191881626844406 | Batches Left: 649\n",
      "EPOCH 1 | Batch 150/798 | Time: 0.0004784146944681803 mins | Loss: 0.053065814077854156 | Batches Left: 648\n",
      "EPOCH 1 | Batch 151/798 | Time: 0.0005126833915710449 mins | Loss: 0.05303223431110382 | Batches Left: 647\n",
      "EPOCH 1 | Batch 152/798 | Time: 0.0005234519640604655 mins | Loss: 0.052842993289232254 | Batches Left: 646\n",
      "EPOCH 1 | Batch 153/798 | Time: 0.0005238533020019531 mins | Loss: 0.05285164341330528 | Batches Left: 645\n",
      "EPOCH 1 | Batch 154/798 | Time: 0.0005237817764282227 mins | Loss: 0.052932679653167725 | Batches Left: 644\n",
      "EPOCH 1 | Batch 155/798 | Time: 0.0004905462265014648 mins | Loss: 0.05284613370895386 | Batches Left: 643\n",
      "EPOCH 1 | Batch 156/798 | Time: 0.0005085150400797526 mins | Loss: 0.053189363330602646 | Batches Left: 642\n",
      "EPOCH 1 | Batch 157/798 | Time: 0.0005455334981282552 mins | Loss: 0.05298656225204468 | Batches Left: 641\n",
      "EPOCH 1 | Batch 158/798 | Time: 0.000523066520690918 mins | Loss: 0.053017884492874146 | Batches Left: 640\n",
      "EPOCH 1 | Batch 159/798 | Time: 0.0004883011182149252 mins | Loss: 0.05295178294181824 | Batches Left: 639\n",
      "EPOCH 1 | Batch 160/798 | Time: 0.000515898068745931 mins | Loss: 0.05261172726750374 | Batches Left: 638\n",
      "EPOCH 1 | Batch 161/798 | Time: 0.0004999836285909017 mins | Loss: 0.052649810910224915 | Batches Left: 637\n",
      "EPOCH 1 | Batch 162/798 | Time: 0.0005551179250081381 mins | Loss: 0.05264494940638542 | Batches Left: 636\n",
      "EPOCH 1 | Batch 163/798 | Time: 0.0005352497100830078 mins | Loss: 0.05256493762135506 | Batches Left: 635\n",
      "EPOCH 1 | Batch 164/798 | Time: 0.0005121509234110515 mins | Loss: 0.052719008177518845 | Batches Left: 634\n",
      "EPOCH 1 | Batch 165/798 | Time: 0.0005008180936177572 mins | Loss: 0.05260587856173515 | Batches Left: 633\n",
      "EPOCH 1 | Batch 166/798 | Time: 0.00048478444417317707 mins | Loss: 0.05262604355812073 | Batches Left: 632\n",
      "EPOCH 1 | Batch 167/798 | Time: 0.0004771669705708822 mins | Loss: 0.05251580476760864 | Batches Left: 631\n",
      "EPOCH 1 | Batch 168/798 | Time: 0.0005656997362772624 mins | Loss: 0.052600108087062836 | Batches Left: 630\n",
      "EPOCH 1 | Batch 169/798 | Time: 0.0005082329114278158 mins | Loss: 0.05282796919345856 | Batches Left: 629\n",
      "EPOCH 1 | Batch 170/798 | Time: 0.000496979554494222 mins | Loss: 0.05264629051089287 | Batches Left: 628\n",
      "EPOCH 1 | Batch 171/798 | Time: 0.0004995505015055339 mins | Loss: 0.05274801328778267 | Batches Left: 627\n",
      "EPOCH 1 | Batch 172/798 | Time: 0.0005108992258707683 mins | Loss: 0.05280572921037674 | Batches Left: 626\n",
      "EPOCH 1 | Batch 173/798 | Time: 0.0004990339279174804 mins | Loss: 0.05292155593633652 | Batches Left: 625\n",
      "EPOCH 1 | Batch 174/798 | Time: 0.000498966375986735 mins | Loss: 0.05271203815937042 | Batches Left: 624\n",
      "EPOCH 1 | Batch 175/798 | Time: 0.0005170027414957682 mins | Loss: 0.05229167267680168 | Batches Left: 623\n",
      "EPOCH 1 | Batch 176/798 | Time: 0.00053329865137736 mins | Loss: 0.052588317543268204 | Batches Left: 622\n",
      "EPOCH 1 | Batch 177/798 | Time: 0.0005003174146016438 mins | Loss: 0.052133556455373764 | Batches Left: 621\n",
      "EPOCH 1 | Batch 178/798 | Time: 0.0005112846692403157 mins | Loss: 0.05205250531435013 | Batches Left: 620\n",
      "EPOCH 1 | Batch 179/798 | Time: 0.0004943370819091797 mins | Loss: 0.05234852060675621 | Batches Left: 619\n",
      "EPOCH 1 | Batch 180/798 | Time: 0.0005128026008605957 mins | Loss: 0.05208031088113785 | Batches Left: 618\n",
      "EPOCH 1 | Batch 181/798 | Time: 0.0004940509796142578 mins | Loss: 0.052247315645217896 | Batches Left: 617\n",
      "EPOCH 1 | Batch 182/798 | Time: 0.0004930337270100912 mins | Loss: 0.05213391035795212 | Batches Left: 616\n",
      "EPOCH 1 | Batch 183/798 | Time: 0.000499733289082845 mins | Loss: 0.05169644206762314 | Batches Left: 615\n",
      "EPOCH 1 | Batch 184/798 | Time: 0.0005237658818562826 mins | Loss: 0.05192866921424866 | Batches Left: 614\n",
      "EPOCH 1 | Batch 185/798 | Time: 0.0005075176556905111 mins | Loss: 0.051897913217544556 | Batches Left: 613\n",
      "EPOCH 1 | Batch 186/798 | Time: 0.0005163470904032389 mins | Loss: 0.05189534276723862 | Batches Left: 612\n",
      "EPOCH 1 | Batch 187/798 | Time: 0.0005054473876953125 mins | Loss: 0.05158059671521187 | Batches Left: 611\n",
      "EPOCH 1 | Batch 188/798 | Time: 0.000596316655476888 mins | Loss: 0.051753997802734375 | Batches Left: 610\n",
      "EPOCH 1 | Batch 189/798 | Time: 0.0004971702893575032 mins | Loss: 0.051654089242219925 | Batches Left: 609\n",
      "EPOCH 1 | Batch 190/798 | Time: 0.00048904816309611 mins | Loss: 0.0514318086206913 | Batches Left: 608\n",
      "EPOCH 1 | Batch 191/798 | Time: 0.0005349159240722656 mins | Loss: 0.05128074064850807 | Batches Left: 607\n",
      "EPOCH 1 | Batch 192/798 | Time: 0.0005342523256937663 mins | Loss: 0.051315948367118835 | Batches Left: 606\n",
      "EPOCH 1 | Batch 193/798 | Time: 0.0006044824918111165 mins | Loss: 0.05125560611486435 | Batches Left: 605\n",
      "EPOCH 1 | Batch 194/798 | Time: 0.0004884680112202962 mins | Loss: 0.05127087980508804 | Batches Left: 604\n",
      "EPOCH 1 | Batch 195/798 | Time: 0.0004974126815795899 mins | Loss: 0.051406677812337875 | Batches Left: 603\n",
      "EPOCH 1 | Batch 196/798 | Time: 0.0004913528760274251 mins | Loss: 0.05115289241075516 | Batches Left: 602\n",
      "EPOCH 1 | Batch 197/798 | Time: 0.0004979530970255534 mins | Loss: 0.05090668424963951 | Batches Left: 601\n",
      "EPOCH 1 | Batch 198/798 | Time: 0.0005150477091471355 mins | Loss: 0.050685375928878784 | Batches Left: 600\n",
      "EPOCH 1 | Batch 199/798 | Time: 0.0004834175109863281 mins | Loss: 0.050745684653520584 | Batches Left: 599\n",
      "EPOCH 1 | Batch 200/798 | Time: 0.0005163868268330892 mins | Loss: 0.050619371235370636 | Batches Left: 598\n",
      "EPOCH 1 | Batch 201/798 | Time: 0.0005046327908833822 mins | Loss: 0.050420183688402176 | Batches Left: 597\n",
      "EPOCH 1 | Batch 202/798 | Time: 0.000505216916402181 mins | Loss: 0.05036960169672966 | Batches Left: 596\n",
      "EPOCH 1 | Batch 203/798 | Time: 0.0004994352658589681 mins | Loss: 0.05035702511668205 | Batches Left: 595\n",
      "EPOCH 1 | Batch 204/798 | Time: 0.0005083441734313965 mins | Loss: 0.050305891782045364 | Batches Left: 594\n",
      "EPOCH 1 | Batch 205/798 | Time: 0.0005342841148376464 mins | Loss: 0.05009909346699715 | Batches Left: 593\n",
      "EPOCH 1 | Batch 206/798 | Time: 0.0004914641380310058 mins | Loss: 0.050312433391809464 | Batches Left: 592\n",
      "EPOCH 1 | Batch 207/798 | Time: 0.0005164861679077149 mins | Loss: 0.05030415952205658 | Batches Left: 591\n",
      "EPOCH 1 | Batch 208/798 | Time: 0.0005512833595275879 mins | Loss: 0.050176624208688736 | Batches Left: 590\n",
      "EPOCH 1 | Batch 209/798 | Time: 0.0004902799924214681 mins | Loss: 0.050201233476400375 | Batches Left: 589\n",
      "EPOCH 1 | Batch 210/798 | Time: 0.0005095005035400391 mins | Loss: 0.050377193838357925 | Batches Left: 588\n",
      "EPOCH 1 | Batch 211/798 | Time: 0.0005723873774210612 mins | Loss: 0.050094977021217346 | Batches Left: 587\n",
      "EPOCH 1 | Batch 212/798 | Time: 0.0004730820655822754 mins | Loss: 0.049959953874349594 | Batches Left: 586\n",
      "EPOCH 1 | Batch 213/798 | Time: 0.0004991014798482259 mins | Loss: 0.050179239362478256 | Batches Left: 585\n",
      "EPOCH 1 | Batch 214/798 | Time: 0.000507215658823649 mins | Loss: 0.050262778997421265 | Batches Left: 584\n",
      "EPOCH 1 | Batch 215/798 | Time: 0.0004964033762613932 mins | Loss: 0.050097670406103134 | Batches Left: 583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     52\u001b[0m     total_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[0;32m---> 53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m, in \u001b[0;36mAudioDataset.__getitem__\u001b[0;34m(self, window_index)\u001b[0m\n\u001b[1;32m     39\u001b[0m audio_index, window_index_in_audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_to_audio_mapping[window_index]\n\u001b[1;32m     40\u001b[0m input_audio_path, target_audio_path, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples[audio_index]\n\u001b[0;32m---> 42\u001b[0m input_waveform, _ \u001b[38;5;241m=\u001b[39m \u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwindow_index_in_audio\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverlap_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m44100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m target_waveform, _ \u001b[38;5;241m=\u001b[39m audiofile\u001b[38;5;241m.\u001b[39mread(target_audio_path, offset\u001b[38;5;241m=\u001b[39m(window_index_in_audio\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverlap_samples)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m44100\u001b[39m, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[1;32m     45\u001b[0m input_waveform \u001b[38;5;241m=\u001b[39m (input_waveform \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;66;03m# Rescale (invertibly) values that go from -1 to 1, to be between 0 and 1\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/audiofile/core/io.py:403\u001b[0m, in \u001b[0;36mread\u001b[0;34m(file, duration, offset, always_2d, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m         stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     signal, sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[43msoundfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# [samples, channels] => [channels, samples]\u001b[39;00m\n\u001b[1;32m    412\u001b[0m signal \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/soundfile.py:285\u001b[0m, in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(file, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m          fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    201\u001b[0m          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    287\u001b[0m         frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[1;32m    288\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/soundfile.py:1205\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1204\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[0;32m-> 1205\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1207\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import gc \n",
    "\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Hyperparameters\n",
    "sequence_length = 882  # Assuming each audio interval has this length\n",
    "batch_size = 8192\n",
    "learning_rate = 0.001\n",
    "print(f\"Number of batches: {len(train_dataset)/batch_size}\")\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class MLPDecoder(nn.Module):\n",
    "    def __init__(self, input_size=sequence_length+2):\n",
    "        super().__init__()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dense1 = nn.Linear(input_size, int(input_size/4))\n",
    "        self.dense2 = nn.Linear(int(input_size/4), int(input_size/8))\n",
    "        self.dense3 = nn.Linear(int(input_size/8), int(input_size/4))\n",
    "        self.dense4 = nn.Linear(int(input_size/4), sequence_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_input = x[0].to(device)\n",
    "        compress_limit_input = x[1].unsqueeze(1).to(device)\n",
    "        peak_reduction_input = x[2].unsqueeze(1).to(device)\n",
    "        concat_embeddings = torch.cat([lstm_input, compress_limit_input, peak_reduction_input], dim=1)\n",
    "\n",
    "        x = self.relu1(self.dense1(concat_embeddings))\n",
    "        x = self.relu2(self.dense2(x))\n",
    "        x = self.relu3(self.dense3(x))\n",
    "        x = self.relu4(self.dense4(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model = MLPDecoder()  # Input size is 1 due to reshaping\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()  # Adjust loss function if needed\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1):\n",
    "    total_batches = len(dataloader)\n",
    "    for batch_idx, (data, label) in enumerate(dataloader):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "\n",
    "        loss = loss_fn(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        batches_done = batch_idx + 1\n",
    "        batches_left = total_batches - batches_done\n",
    "        \n",
    "        print(f\"EPOCH {epoch+1} | Batch {batch_idx+1}/{total_batches} | Time: {(end_time - start_time)/60.0} mins | Loss: {loss.item()} | Batches Left: {batches_left}\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IS THE SHUFFLE PARAMETER MESSING UP MY \"WINDOW INDEX\" STUFF INSIDE THE DATASET CLASS ? AM I COMPUTING THE INDICES OF AUDIO CLIPS, JUST TO HAVE THIS NEGATED BY A SHUFFLING MECHANISM WHICH MEANS THE INDICES ARE ALL MIXED UP? \n",
    "\n",
    "to confirm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
